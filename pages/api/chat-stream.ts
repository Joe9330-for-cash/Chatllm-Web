import { NextApiRequest, NextApiResponse } from 'next';
import { SUPPORTED_MODELS, SupportedModel } from './chat';
import ModelRouter from '../../lib/model-router';
import https from 'https';

// æ”¹è¿›çš„HTTPSä»£ç†é…ç½®ï¼ŒåŒ…å«è¿æ¥æ± å’Œè¶…æ—¶è®¾ç½®
const httpsAgent = new https.Agent({
  rejectUnauthorized: process.env.NODE_ENV !== 'development',
  keepAlive: true,
  keepAliveMsecs: 30000,
  maxSockets: 10,
  maxFreeSockets: 5,
  timeout: 60000 // 60ç§’è¶…æ—¶
});

// é‡è¯•é…ç½®
const RETRY_CONFIG = {
  maxRetries: 3,
  baseDelay: 1000, // 1ç§’åŸºç¡€å»¶è¿Ÿ
  maxDelay: 8000,  // æœ€å¤§8ç§’å»¶è¿Ÿ
  retryableErrors: ['ECONNRESET', 'ENOTFOUND', 'ECONNREFUSED', 'ETIMEDOUT', 'EHOSTUNREACH']
};

// å»¶è¿Ÿå‡½æ•°
const delay = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

// è®¡ç®—æŒ‡æ•°é€€é¿å»¶è¿Ÿ
const getRetryDelay = (attempt: number): number => {
  const delay = Math.min(
    RETRY_CONFIG.baseDelay * Math.pow(2, attempt),
    RETRY_CONFIG.maxDelay
  );
  // æ·»åŠ éšæœºæŠ–åŠ¨
  return delay + Math.random() * 1000;
};

interface ChatMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

interface ChatRequest {
  model: SupportedModel;
  messages: ChatMessage[];
  enableSmartRouting?: boolean; // æ–°å¢ï¼šå¯ç”¨æ™ºèƒ½è·¯ç”±é€‰é¡¹
}

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse
) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  let model: SupportedModel = 'chatgpt-4o-latest'; // é»˜è®¤æ¨¡å‹
  
  try {
    const requestData: ChatRequest = req.body;
    const originalModel = requestData.model;
    const messages = requestData.messages;
    const enableSmartRouting = requestData.enableSmartRouting ?? true; // é»˜è®¤å¯ç”¨æ™ºèƒ½è·¯ç”±
    
    // è·å–æ¨¡å‹è·¯ç”±å™¨å®ä¾‹
    const modelRouter = ModelRouter.getInstance();
    
    // æ™ºèƒ½æ¨¡å‹é€‰æ‹©
    if (enableSmartRouting && messages.length > 0) {
      const userMessage = messages[messages.length - 1];
      if (userMessage.role === 'user') {
        const suggestedModel = modelRouter.selectOptimalModel(userMessage.content);
        if (suggestedModel !== originalModel) {
          console.log(`[Smart Router] ğŸ¯ æ™ºèƒ½è·¯ç”±: ${originalModel} -> ${suggestedModel}`);
          model = suggestedModel;
        } else {
          console.log(`[Smart Router] âœ… ä¿æŒåŸé€‰æ‹©: ${originalModel}`);
          model = originalModel;
        }
      } else {
        model = originalModel;
      }
    } else {
      model = originalModel;
    }
    
    // è·å–æ¨¡å‹ä¸“å±é…ç½®
    const modelConfig = modelRouter.getModelConfig(model);

    // éªŒè¯æ¨¡å‹æ˜¯å¦æ”¯æŒ
    if (!SUPPORTED_MODELS[model]) {
      return res.status(400).json({ 
        error: `Unsupported model: ${model}` 
      });
    }

    console.log(`[Stream API] å¼€å§‹æµå¼è°ƒç”¨æ¨¡å‹: ${model}`);
    
    // è®°å½•å¼€å§‹æ—¶é—´å’Œæ€§èƒ½è¿½è¸ª
    const startTime = Date.now();
    const performanceTracker = {
      requestStart: startTime,
      llmConnectionStart: 0,
      llmConnectionEnd: 0,
      firstTokenTime: 0,
      firstContentTime: 0,
      responseComplete: 0
    };

    // è®¾ç½®SSEå“åº”å¤´
    res.writeHead(200, {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Headers': 'Content-Type',
    });

    // å‡†å¤‡APIè¯·æ±‚
    const apiUrl = process.env.OPENAI_API_BASE || 'https://api.laozhang.ai/v1/chat/completions';
    const apiKey = process.env.OPENAI_API_KEY || 'sk-fHiGcdKRdV7SykaZB0D755D91dEe48038f1aB0B7556fE2Fc';

    // æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•çš„é”™è¯¯
    const isRetryableError = (error: any): boolean => {
      if (!error) return false;
      
      // æ£€æŸ¥ç½‘ç»œé”™è¯¯ä»£ç 
      const code = error.code || error.cause?.code;
      if (RETRY_CONFIG.retryableErrors.includes(code)) {
        return true;
      }
      
      // æ£€æŸ¥é”™è¯¯æ¶ˆæ¯
      const message = error.message || '';
      return message.includes('fetch failed') || 
             message.includes('socket disconnected') || 
             message.includes('ECONNRESET') ||
             message.includes('network');
    };

    // å¸¦é‡è¯•çš„fetchå‡½æ•°
    const fetchWithRetry = async (url: string, options: any, attempt: number = 0): Promise<Response> => {
      try {
        console.log(`[Stream API] å°è¯•è¿æ¥ (${attempt + 1}/${RETRY_CONFIG.maxRetries + 1}): ${model}`);
        
        // è®°å½•LLMè¿æ¥å¼€å§‹æ—¶é—´
        if (attempt === 0) {
          performanceTracker.llmConnectionStart = Date.now();
        }
        
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), modelConfig.timeout); // ä½¿ç”¨æ¨¡å‹é…ç½®çš„è¶…æ—¶æ—¶é—´
        
        const response = await fetch(url, {
          ...options,
          signal: controller.signal,
          // @ts-ignore - å¼€å‘ç¯å¢ƒSSLé…ç½®
          ...(process.env.NODE_ENV === 'development' && { agent: httpsAgent }),
          // ç½‘ç»œè¿æ¥ä¼˜åŒ–
          keepalive: true, // ä¿æŒè¿æ¥æ´»è·ƒ
          cache: 'no-cache', // ç¦ç”¨ç¼“å­˜ï¼Œç¡®ä¿å®æ—¶æ€§
        });
        
        clearTimeout(timeoutId);
        
        // è®°å½•LLMè¿æ¥å®Œæˆæ—¶é—´
        performanceTracker.llmConnectionEnd = Date.now();
        
        return response;
        
      } catch (error: any) {
        console.log(`[Stream API] è¿æ¥å¤±è´¥ (å°è¯• ${attempt + 1}): ${error.message}`);
        
        if (attempt < RETRY_CONFIG.maxRetries && isRetryableError(error)) {
          const delayMs = getRetryDelay(attempt);
          console.log(`[Stream API] ${delayMs}msåé‡è¯•...`);
          await delay(delayMs);
          return fetchWithRetry(url, options, attempt + 1);
        }
        
        throw error;
      }
    };

    const response = await fetchWithRetry(apiUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
        'User-Agent': 'ChatLLM-Web/1.0',
        'Connection': 'keep-alive',
        'Accept': 'text/event-stream', // æ˜ç¡®æ¥å—äº‹ä»¶æµ
        'Cache-Control': 'no-cache', // ç¦ç”¨ç¼“å­˜
        'Accept-Encoding': 'gzip, deflate', // å¯ç”¨å‹ç¼©
      },
      body: JSON.stringify({
        model: SUPPORTED_MODELS[model],
        messages, // ç›´æ¥ä¼ é€’ç”¨æˆ·çš„messagesï¼Œä¸æ·»åŠ é¢å¤–çš„system prompt
        stream: true, // å¯ç”¨æµå¼è¾“å‡º
        max_tokens: modelConfig.max_tokens, // ä½¿ç”¨æ¨¡å‹é…ç½®çš„æœ€å¤§tokenæ•°
        temperature: modelConfig.temperature, // ä½¿ç”¨æ¨¡å‹é…ç½®çš„æ¸©åº¦
        top_p: modelConfig.top_p,
        frequency_penalty: modelConfig.frequency_penalty,
        presence_penalty: modelConfig.presence_penalty,
        stream_options: modelConfig.stream_options, // ä½¿ç”¨æ¨¡å‹é…ç½®çš„æµé€‰é¡¹
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.log(`[Stream API] âŒ ${model}: APIé”™è¯¯ ${response.status}`);
      res.write(`data: ${JSON.stringify({ error: `API Error: ${response.status} - ${errorText}` })}\n\n`);
      res.end();
      return;
    }

    console.log(`[Stream API] âœ… ${model}: å¼€å§‹æ¥æ”¶æµå¼æ•°æ®`);

    // å‘é€æ€è€ƒå¼€å§‹ä¿¡å·ç»™å‰ç«¯ - DeepSeek R1ä¸“é¡¹ä¼˜åŒ–
    if (model === 'deepseek-r1') {
      res.write(`data: ${JSON.stringify({ 
        type: 'thinking_start',
        model: model,
        timestamp: Date.now()
      })}\n\n`);
    }

    // å¤„ç†æµå¼å“åº”
    const reader = response.body?.getReader();
    const decoder = new TextDecoder();
    let buffer = '';
    let contentBuffer = ''; // å†…å®¹ç¼“å†²åŒºï¼Œç”¨äºæ‰¹é‡å‘é€
    let lastFlushTime = Date.now();
    let totalTokens = 0; // Tokenç»Ÿè®¡
    let generatedTokens = 0; // æ–°å¢ï¼šå®é™…ç”Ÿæˆçš„tokenæ•°ï¼ˆcompletion + reasoningï¼‰
    let promptTokens = 0; // æ–°å¢ï¼šè¾“å…¥tokenæ•°
    let completionTokens = 0; // æ–°å¢ï¼šå®Œæˆtokenæ•°
    let reasoningTokens = 0; // æ–°å¢ï¼šæ€è€ƒtokenæ•°
    let firstTokenReceived = false; // ç¬¬ä¸€ä¸ªtokenæ ‡è®°
    let firstContentReceived = false; // ç¬¬ä¸€ä¸ªå†…å®¹æ ‡è®°

    if (!reader) {
      res.write(`data: ${JSON.stringify({ error: 'No response body' })}\n\n`);
      res.end();
      return;
    }

    const flushBuffer = () => {
      if (contentBuffer) {
        res.write(`data: ${JSON.stringify({ 
          content: contentBuffer,
          model: model 
        })}\n\n`);
        contentBuffer = '';
        lastFlushTime = Date.now();
      }
    };

    while (true) {
      const { value, done } = await reader.read();
      if (done) {
        // å‘é€å‰©ä½™ç¼“å†²å†…å®¹
        flushBuffer();
        break;
      }

      buffer += decoder.decode(value, { stream: true });
      const lines = buffer.split('\n');
      buffer = lines.pop() || '';

      for (const line of lines) {
        if (line.trim() === '') continue;
        if (line.startsWith('data: ')) {
          const dataStr = line.slice(6);
          if (dataStr.trim() === '[DONE]') {
            flushBuffer(); // å‘é€å‰©ä½™å†…å®¹
            
            // è®°å½•å“åº”å®Œæˆæ—¶é—´
            performanceTracker.responseComplete = Date.now();
            
            // è®¡ç®—å“åº”æ—¶é—´å¹¶å‘é€ç»Ÿè®¡ä¿¡æ¯
            const responseTime = Date.now() - startTime;
            
            // ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š - ç¡®ä¿æ—¶é—´éƒ½æ˜¯æ­£æ•°
            const performanceReport = {
              totalTime: responseTime,
              connectionTime: Math.max(0, performanceTracker.llmConnectionEnd - performanceTracker.llmConnectionStart),
              timeToFirstToken: performanceTracker.firstTokenTime ? Math.max(0, performanceTracker.firstTokenTime - performanceTracker.llmConnectionEnd) : 0,
              timeToFirstContent: performanceTracker.firstContentTime ? Math.max(0, performanceTracker.firstContentTime - performanceTracker.llmConnectionEnd) : 0,
              streamingTime: Math.max(0, performanceTracker.responseComplete - (performanceTracker.firstContentTime || performanceTracker.llmConnectionEnd))
            };
            
            // è¾“å‡ºè¯¦ç»†æ€§èƒ½æŠ¥å‘Šåˆ°ç»ˆç«¯
            console.log('\n' + 'â•'.repeat(80));
            console.log(`ğŸš€ **${model.toUpperCase()} æ€§èƒ½åˆ†ææŠ¥å‘Š**`);
            console.log('â•'.repeat(80));
            console.log(`ğŸ“Š æ€»è€—æ—¶: ${responseTime}ms`);
            console.log(`ğŸ”— LLMè¿æ¥: ${performanceReport.connectionTime}ms`);
            console.log(`âš¡ é¦–tokenå»¶è¿Ÿ: ${performanceReport.timeToFirstToken}ms`);
            console.log(`ğŸ’¬ é¦–å†…å®¹å»¶è¿Ÿ: ${performanceReport.timeToFirstContent}ms`);
            console.log(`ğŸ“ æµå¼è¾“å‡º: ${performanceReport.streamingTime}ms`);
            console.log(`ğŸ¯ ç”Ÿæˆé€Ÿç‡: ${generatedTokens > 0 ? (generatedTokens / (responseTime / 1000)).toFixed(1) : 0} tokens/s`);
            console.log(`ğŸ“ˆ Tokenç»Ÿè®¡: ç”Ÿæˆ${generatedTokens} | è¾“å…¥${promptTokens} | æ€»è®¡${totalTokens}`);
            console.log('â•'.repeat(80) + '\n');
            
            console.log(`[Stream API] âœ… ${model}: æµå¼è¾“å‡ºå®Œæˆï¼Œè€—æ—¶: ${responseTime}ms, Generated: ${generatedTokens}, Total: ${totalTokens}`);
            
            // æ›´æ–°æ¨¡å‹æ€§èƒ½ç»Ÿè®¡
            if (enableSmartRouting && messages.length > 0) {
              const userMessage = messages[messages.length - 1];
              if (userMessage.role === 'user') {
                const contentHash = modelRouter.selectOptimalModel(userMessage.content); // é‡æ–°ç”Ÿæˆhashç”¨äºç»Ÿè®¡
                modelRouter.updateModelPerformance(model, contentHash, responseTime, true);
              }
            }
            
            res.write(`data: ${JSON.stringify({ 
              done: true, 
              responseTime,
              totalTokens,
              generatedTokens, // æ–°å¢ï¼šå®é™…ç”Ÿæˆçš„tokens
              promptTokens, // æ–°å¢ï¼šè¾“å…¥tokens
              completionTokens, // æ–°å¢ï¼šå®Œæˆtokens
              reasoningTokens, // æ–°å¢ï¼šæ€è€ƒtokens
              usage: { // æ–°å¢ï¼šå®Œæ•´usageä¿¡æ¯
                total_tokens: totalTokens,
                prompt_tokens: promptTokens,
                completion_tokens: completionTokens,
                generated_tokens: generatedTokens,
                reasoning_tokens: reasoningTokens
              },
              model,
              originalModel, // æ–°å¢ï¼šåŸå§‹è¯·æ±‚çš„æ¨¡å‹
              smartRouting: enableSmartRouting, // æ–°å¢ï¼šæ™ºèƒ½è·¯ç”±çŠ¶æ€
              routerStats: modelRouter.getStats() // æ–°å¢ï¼šè·¯ç”±å™¨ç»Ÿè®¡ä¿¡æ¯
            })}\n\n`);
            res.end();
            return;
          }

                      try {
            const chunk = JSON.parse(dataStr);
            const delta = chunk.choices?.[0]?.delta;
            
            // è®°å½•ç¬¬ä¸€ä¸ªtokenæ—¶é—´
            if (!firstTokenReceived && (delta?.content || delta?.reasoning)) {
              performanceTracker.firstTokenTime = Date.now();
              firstTokenReceived = true;
            }
            
            // å¤„ç†usageç»Ÿè®¡ä¿¡æ¯
            if (chunk.usage) {
              totalTokens = chunk.usage.total_tokens || 0;
              completionTokens = chunk.usage.completion_tokens || 0;
              promptTokens = chunk.usage.prompt_tokens || 0;
              reasoningTokens = chunk.usage.completion_tokens_details?.reasoning_tokens || 0;
              generatedTokens = completionTokens + reasoningTokens;
              
              console.log(`[Stream API] ${model} Tokenç»Ÿè®¡:`, {
                prompt_tokens: promptTokens,
                completion_tokens: completionTokens,
                reasoning_tokens: reasoningTokens,
                generated_tokens: generatedTokens,
                total_tokens: totalTokens
              });
            }
            
            // æœ‰äº›æ¨¡å‹åœ¨æœ€åä¸€ä¸ªchunkä¸­è¿”å›usageä¿¡æ¯
            if (chunk.choices?.[0]?.finish_reason && !totalTokens) {
              // å¦‚æœæ²¡æœ‰usageä¿¡æ¯ï¼Œå°è¯•ä»å…¶ä»–å­—æ®µè·å–
              if (chunk.usage) {
                totalTokens = chunk.usage.total_tokens || 0;
                completionTokens = chunk.usage.completion_tokens || 0;
                promptTokens = chunk.usage.prompt_tokens || 0;
                reasoningTokens = chunk.usage.completion_tokens_details?.reasoning_tokens || 0;
                generatedTokens = completionTokens + reasoningTokens;
              }
            }
            
            if (delta) {
              // å¤„ç†æ€è€ƒè¿‡ç¨‹ï¼ˆDeepSeek R1ä¸“ç”¨ï¼‰- ä¼˜åŒ–ç‰ˆæœ¬
              if (delta.reasoning && model === 'deepseek-r1') {
                // ä¼˜åŒ–ï¼šæ‰¹é‡å‘é€æ€è€ƒè¿‡ç¨‹ï¼Œå‡å°‘ç½‘ç»œå¾€è¿”
                const reasoningChunks = delta.reasoning.split('\n').filter((chunk: string) => chunk.trim());
                if (reasoningChunks.length > 0) {
                  res.write(`data: ${JSON.stringify({ 
                    type: 'reasoning',
                    content: reasoningChunks.join('\n'),
                    model: model,
                    chunks: reasoningChunks.length
                  })}\n\n`);
                }
              }
              
              // å¤„ç†æœ€ç»ˆå›ç­”å†…å®¹
              if (delta.content) {
                // è®°å½•ç¬¬ä¸€ä¸ªå†…å®¹æ—¶é—´
                if (!firstContentReceived) {
                  performanceTracker.firstContentTime = Date.now();
                  firstContentReceived = true;
                }
                
                contentBuffer += delta.content;
                
                // ä½¿ç”¨æ¨¡å‹è·¯ç”±å™¨çš„æµå¼é…ç½®
                const flushThreshold = modelConfig.flushThreshold || 1;
                const flushInterval = modelConfig.flushInterval || 10;
                
                // å½“ç¼“å†²åŒºè¾¾åˆ°é˜ˆå€¼æˆ–è¶…è¿‡æ—¶é—´é—´éš”æ—¶å‘é€
                if (contentBuffer.length >= flushThreshold || 
                    Date.now() - lastFlushTime > flushInterval) {
                  flushBuffer();
                }
              }
            }
          } catch (e) {
            // å¿½ç•¥JSONè§£æé”™è¯¯
          }
        }
      }
    }

  } catch (error: any) {
    const errorCode = error.code || error.cause?.code;
    const errorMessage = error.message || 'Unknown error';
    
    console.log(`[Stream API] âŒ æµå¼å¤„ç†å¼‚å¸¸:`, {
      model,
      error: errorMessage,
      code: errorCode,
      stack: error.stack?.substring(0, 500) // æˆªå–å‰500å­—ç¬¦çš„å †æ ˆ
    });

    // æ ¹æ®é”™è¯¯ç±»å‹æä¾›ä¸åŒçš„é”™è¯¯ä¿¡æ¯
    let userFriendlyMessage = 'æµå¼å¤„ç†å¤±è´¥';
    let retryable = false;

    if (RETRY_CONFIG.retryableErrors.includes(errorCode)) {
      userFriendlyMessage = 'ç½‘ç»œè¿æ¥ä¸ç¨³å®šï¼Œè¯·ç¨åé‡è¯•';
      retryable = true;
    } else if (errorMessage.includes('abort')) {
      userFriendlyMessage = 'è¯·æ±‚è¶…æ—¶ï¼Œè¯·é‡è¯•';
      retryable = true;
    } else if (errorMessage.includes('fetch failed')) {
      userFriendlyMessage = 'APIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•';
      retryable = true;
    } else if (errorMessage.includes('socket disconnected')) {
      userFriendlyMessage = 'è¿æ¥ä¸­æ–­ï¼Œè¯·é‡è¯•';
      retryable = true;
    }

    // å¦‚æœå“åº”è¿˜æ²¡æœ‰å¼€å§‹ï¼Œå‘é€JSONé”™è¯¯
    if (!res.headersSent) {
      res.status(500).json({ 
        error: userFriendlyMessage,
        details: errorMessage,
        code: errorCode,
        retryable,
        model
      });
    } else {
      // å¦‚æœå·²ç»å¼€å§‹æµå¼å“åº”ï¼Œå‘é€SSEé”™è¯¯äº‹ä»¶
      try {
        res.write(`data: ${JSON.stringify({ 
          error: userFriendlyMessage,
          details: errorMessage,
          code: errorCode,
          retryable,
          model,
          timestamp: Date.now()
        })}\n\n`);
        res.end();
      } catch (writeError) {
        console.error(`[Stream API] å†™å…¥é”™è¯¯å“åº”å¤±è´¥:`, writeError);
        // å¼ºåˆ¶ç»“æŸå“åº”
        res.end();
      }
    }
  }
} 